# -*- coding: utf-8 -*-
"""initial_data_processing

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1XzFdIosViqs8FSAKgVyh84TcLTkICE6i

# **Initial File Parsing and Data Processing**

---

**Repos**

TOXIFY: https://github.com/tijeco/toxify

ToxClassifier: https://github.com/rgacesa/ToxClassifier


---
"""

# -----------------------------------------------------------------------------
# INSTALLS
!pip install biopython

# -----------------------------------------------------------------------------
# IMPORTS

import Bio as bio
import csv
import io
import itertools as ite
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import pickle
import os.path
import random
import re
import seaborn as sns
import sklearn
import statistics

from Bio import SeqIO
from Bio.SeqIO.FastaIO import SimpleFastaParser
from collections import OrderedDict
from textwrap import wrap
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score
from sklearn.model_selection import train_test_split, StratifiedShuffleSplit
from sklearn.utils import resample

random_seed = 273
random.seed(random_seed)

# FILEPATHS
# -----------------------------------------------------------------------------
# INPUT files

# training data
ip_toxic_fasta = '/content/drive/My Drive/UoS/Year3/COM3001/Data/pre.venom.fasta'
ip_atoxic_fasta = '/content/drive/My Drive/UoS/Year3/COM3001/Data/pre.NOT.venom.fasta'

# reference values files
ip_amino_acid = '/content/drive/My Drive/UoS/Year3/COM3001/Data/ReferenceValues/amino_acid_codes.csv'
ip_atchley = '/content/drive/My Drive/UoS/Year3/COM3001/Data/ReferenceValues/atchley.csv'

# -----------------------------------------------------------------------------
# OUTPUT files
op_train_complete = '/content/drive/My Drive/UoS/Year3/COM3001/Data/dataframes/train_complete.pickle'
op_train_atchley_means = '/content/drive/My Drive/UoS/Year3/COM3001/Data/dataframes/train_atchley_mean.pickle'

# k-fold cross validation dictionaries
op_5_fold_p10 = '/content/drive/My Drive/UoS/Year3/COM3001/Data/CrossVal/5_fold_p10.pickle'
op_5_fold_p15 = '/content/drive/My Drive/UoS/Year3/COM3001/Data/CrossVal/5_fold_p15.pickle'
op_5_fold_p20 = '/content/drive/My Drive/UoS/Year3/COM3001/Data/CrossVal/5_fold_p20.pickle'

op_10_fold_p10 = '/content/drive/My Drive/UoS/Year3/COM3001/Data/CrossVal/10_fold_p10.pickle'
op_10_fold_p15 = '/content/drive/My Drive/UoS/Year3/COM3001/Data/CrossVal/10_fold_p15.pickle'
op_10_fold_p20 = '/content/drive/My Drive/UoS/Year3/COM3001/Data/CrossVal/10_fold_p20.pickle'

op_15_fold_p10 = '/content/drive/My Drive/UoS/Year3/COM3001/Data/CrossVal/15_fold_p10.pickle'
op_15_fold_p15 = '/content/drive/My Drive/UoS/Year3/COM3001/Data/CrossVal/15_fold_p15.pickle'
op_15_fold_p20 = '/content/drive/My Drive/UoS/Year3/COM3001/Data/CrossVal/15_fold_p20.pickle'

op_20_fold_p10 = '/content/drive/My Drive/UoS/Year3/COM3001/Data/CrossVal/20_fold_p10.pickle'
op_20_fold_p15 = '/content/drive/My Drive/UoS/Year3/COM3001/Data/CrossVal/20_fold_p15.pickle'
op_20_fold_p20 = '/content/drive/My Drive/UoS/Year3/COM3001/Data/CrossVal/20_fold_p20.pickle'

# FUNCTIONS START
# -----------------------------------------------------------------------------

# COMMON VARIABLE NAMES
invalid_letters = ['B', 'J', 'O', 'U', 'X', 'Z']

# GENERAL
# save df to a csv file
def df_to_csv(df, outpath, sep):
  df.to_csv(outpath, sep, encoding='utf-8')

# read in csv to df
def cvs_to_df(inpath, col_idx):
  return pd.read_csv(inpath, index_col=col_idx, encoding='utf-8')

# splits sequence and saves to a dictionary
def split_seq(sequence):
  return {'letter': [char for char in sequence]}

# opens fasta file and creates dataframe
def parse_fasta(path_fasta, toxic):
  protein_sequences = []
  with open(path_fasta) as fasta_file:
    for title, sequence in SimpleFastaParser(fasta_file):
      if not any(ele in sequence for ele in invalid_letters):
        protein_sequences.append( ProteinSequence(title.split(None, 1)[0], toxic, len(sequence), split_seq(sequence)) )
  return protein_sequences

# for writing and reading data to/from a binary file
def pickle_method(fname, method, context):
    if method == 'wb':
        return pickle.dump(context, open(fname, method))
    elif method == 'rb':
        return pickle.load(open(fname, method))


# SUMMARY FUNCTIONS
def describe_df(df, decimal):
    return df.describe().T[['mean', 'std', 'max','min', '25%','50%', '75%']].round(decimals=decimal)


# GRAPH FUNCTIONS

# make distribution plot
def dist_graph(df, x_dim, y_dim, x_axis_col, title, x_label, y_label, colour, bins):
  sns.set(style='whitegrid')
  fig = plt.subplots(figsize=(x_dim, y_dim))
  dist = np.asarray(df[[x_axis_col]].values.tolist()).ravel()
  ax = sns.distplot(df[x_axis_col],
                       bins=bins, kde=True,
                       kde_kws={"color": "k", "lw": 2, "label": "KDE"},
                       color=colour)
  ax.set_title(title, fontsize=26)
  ax.set_xlabel(x_label, fontsize=16)
  ax.set_ylabel(y_label, fontsize=16)

a = [1, 3, 5, 44, 5]
b = ['a', 'd', 't', 'o', 'p']

for i, (vol1, vol2) in enumerate(zip(a, b):
  print(i,vol1, vol2)

"""# **Atchley**

---
"""

# loading atchley csv data and turning to dict
df_atchley = cvs_to_df(ip_atchley, 0)
df_atchley.rename(columns={'amino.acid': 'amino_acid'}, inplace=True)
df_atchley.set_index('amino_acid', inplace=True)
for col in df_atchley['f1': 'f5']:
  df_atchley[col] = df_atchley[col].apply(lambda x: re.sub(r'[^\x00-\x7F]+','-', x)).astype(float)
dict_atchley = df_atchley.T.to_dict('list')

dict_atchley

"""# **Defining Objects**

---
"""

# PROTEIN PROCESSING FUNCTIONS START
# -----------------------------------------------------------------------------

# PROTEIN CLASS
class ProteinSequence:
  def __init__(self, identifier, toxic, length, sequence):
    self.identifier = identifier
    self.toxic = toxic
    self.length = length
    self.sequence_dict = sequence

  def to_dict(self):
    return {
        'identifier': self.identifier,
        'toxic': self.toxic,
        'length': self.length,
        'letters': self.sequence_dict
    }

# -----------------------------------------------
# APPENDING RAW ATCHLEY VALUES
# get atchley values
def get_atchley_vals(letters, idx):
  return [float(dict_atchley.get(i)[idx]) for i in letters]

# matches each atchley value to each amino acid
def get_atchley_values(seq_dict):
  sequence = seq_dict.get('letter')
  seq_dict['f1'] = get_atchley_vals(sequence, 0)
  seq_dict['f2'] = get_atchley_vals(sequence, 1)
  seq_dict['f3'] = get_atchley_vals(sequence, 2)
  seq_dict['f4'] = get_atchley_vals(sequence, 3)
  seq_dict['f5'] = get_atchley_vals(sequence, 4)

# appends the atchley values to the dictionary of a ProteinSequence object
def append_atchley_values(protein_seq_list):
  for protein in protein_seq_list:
    get_atchley_values(protein.sequence_dict)

# -----------------------------------------------
# APPENDING CHANGES IN ATCHLEY VALUES
# calculates sequential change for single atchley value
def get_change_list(atchley_list):
  atchley_list.insert(0, 0)
  change_list = [i for i in (np.diff(atchley_list))]
  atchley_list.pop(0)
  return change_list

# calculates sequential change for each atchley value
def get_atchley_change(seq_dict):
  seq_dict['f1_d'] = get_change_list(seq_dict.get('f1'))
  seq_dict['f2_d'] = get_change_list(seq_dict.get('f2'))
  seq_dict['f3_d'] = get_change_list(seq_dict.get('f3'))
  seq_dict['f4_d'] = get_change_list(seq_dict.get('f4'))
  seq_dict['f5_d'] = get_change_list(seq_dict.get('f5'))

# appends the sequential changes in atchley values to the existing dictionary
def append_atchley_change(protein_seq_list):
  for protein in protein_seq_list:
    get_atchley_change(protein.sequence_dict)

"""# **Loading and cleaning Data**


1.   Removing sequences that contains letters not in Atchley dictionary
2.   Downsampling




---
"""

# parsing toxic and atoxic data from fasta files
toxic_list = parse_fasta(ip_toxic_fasta, 1)
atoxic_list = parse_fasta(ip_atoxic_fasta, 0)

total_toxic_seqs = len(toxic_list)
print('Total toxic sequences: ', total_toxic_seqs)
print('Total atoxic sequences: ', len(atoxic_list))

# # adding 'ProteinSequence' list to df
# df_toxic = pd.DataFrame.from_records([p.to_dict() for p in toxic_list])
# df_atoxic = pd.DataFrame.from_records([p.to_dict() for p in atoxic_list])

# # df_toxic.head(5)
# df_atoxic.head(5)

"""**Distribution analysis pre downsample**"""

# # data distribution for toxic class
# dist_graph(df_toxic, 14, 8, 'length',
#            'Distribution of toxic protein sequences lengths',
#            'Sequence Length', '', 'seagreen', 62)

# # raw distribution of atoxic protein sequence lengths
# dist_graph(df_atoxic, 18, 8, 'length',
#            'Distribution of atoxic protein sequences lengths pre downsampling',
#            'Sequence Length', '', 'seagreen', 200)

"""# **Downsampling**"""

# downsamplig atoxic
atoxic_downsampled = resample(atoxic_list, replace=False, n_samples=total_toxic_seqs, random_state=random_seed)

# print test
print('Total protein sequences in atoxic list post downsampling: ', len(atoxic_downsampled))

"""Comparing pre and post downsmaple distrbutions for sequence length"""

# # downsampled distribution of atoxic protein sequence lengths
# dist_graph(df_atoxic_downsampled, 18, 8, 'length',
#            'Distribution of atoxic protein sequences lengths post downsampling',
#            'Sequence Length', '', 'seagreen', 80)

# # boxplots
# x = 2
# y = 12
# vert = True
# # atoxic pre downsample
# df_atoxic[df_atoxic.columns[2:].to_list()].boxplot(vert=vert)
# plt.gcf().set_size_inches(x,y)
# plt.title('Pre-downsampling atoxic sequences distribution')
# plt.show()
# print(df_atoxic['length'].describe().T[['mean', 'std', 'max','min', '25%', '50%', '75%']].round(decimals=2))
# print('\n')

# # atoxic post downsample
# df_atoxic_downsampled[df_atoxic_downsampled.columns[2:].to_list()].boxplot(vert=vert)
# plt.gcf().set_size_inches(x,y)
# plt.title('Post-downsampling atoxic sequences distribution')
# plt.show()
# print(df_atoxic_downsampled['length'].describe().T[['mean', 'std', 'max','min', '25%', '50%', '75%']].round(decimals=2))
# print('\n')

# # toxic
# df_toxic[df_toxic.columns[2:].to_list()].boxplot(vert=vert)
# plt.gcf().set_size_inches(x,y)
# plt.title('Toxic sequences distribution')
# plt.show()
# print(df_toxic['length'].describe().T[['mean', 'std', 'max','min', '25%', '50%', '75%']].round(decimals=2))

"""# **Joining 2 datasets**"""

# appending toxic and atoxic 'ProteinSequence' lists
proteins = toxic_list + atoxic_downsampled
print(len(proteins))

# appending atchley values
append_atchley_values(proteins)
append_atchley_change(proteins)

print(len(proteins[0].sequence_dict))

# print test
print(type(proteins[0].sequence_dict.get('f5_d')[0]))

# adding proteins list to dataframe, each dictionary to
df = pd.DataFrame.from_records([p.to_dict() for p in proteins])
df = df.drop('letters', 1).assign(**df['letters'].dropna().apply(pd.Series))
df

# # pickling file
# pickle_method(op_train_complete, 'wb', df)

# unpickling method
df = pickle_method(op_train_complete, 'rb', '')
df

print('Checking for null columns:\n')
df.isnull().sum()

print('Checking value counts for each class:\n1 == toxic\n0 == atoxic\n----------')
df['toxic'].value_counts()

"""**Preprocessing**"""

# creating a df with mean values of atchley dictionaries
df_means = df.copy()
df_means

# calculating means of atchley values
def get_atchley_means(df, start_col, end_col):
  col = start_col
  while (col <= end_col):
    for i, row in df.iterrows():
      df.at[i, df.columns[col]] = statistics.mean(df.at[i, df.columns[col]])
    col += 1

# df_means_test = df_means_test.apply(lambda x: [statistics.mean(i) for i in x] if x.isNumeric()
get_atchley_means(df_means, 4, 13)
df_means

# # pickling file
# pickle_method(op_train_atchley_means, 'wb', df_means)

# unpickling file
df_means = pickle_method(op_train_atchley_means, 'rb', '')

print(df_means['f1'][0])

df_means

"""---


# **Training vs Validation splitting**
"""

# split into training and validation sets
y_labels = df_means['toxic']
x_features = df_means.drop(['toxic', 'identifier', 'letter'], axis=1)

# checking length
print(len(y_labels))
print(len(x_features))

# get splits from k fold
def get_kfold_splits(save_file, cv_splits, val_size):
  fold_dict = {}
  i = 1
  sss = StratifiedShuffleSplit(n_splits=cv_splits, test_size=val_size, random_state=random_seed)
  print(sss)
  print('Number of k-fold splits: ', sss.get_n_splits())
  for train_idx, val_idx in sss.split(x_features, y_labels):
    x_train, x_val = x_features.iloc[train_idx], x_features.iloc[val_idx]
    y_train, y_val = y_labels.iloc[train_idx], y_labels.iloc[val_idx]
    fold_dict[str(i)] = [x_train, x_val, y_train, y_val]
    i += 1
  pickle_method(save_file, 'wb', fold_dict)
  return fold_dict

# splitting variables
cv_splits = 5
val_size = 0.20

# getting k-fold splits
# indexes:
# 0 -> x_train_vectorised
# 1 -> x_val_vectorised
# 2 -> y_train
# 3 -> y_val
k_folds_dict = get_kfold_splits(op_5_fold_p20, cv_splits, val_size)

# loading k-fold files

fold_5_10p = pickle_method(op_5_fold_p10, 'rb', '')
print('k-folds: ', len(fold_5_10p))
fold_5_15p = pickle_method(op_5_fold_p15, 'rb', '')
print('k-folds: ', len(fold_5_15p))
fold_5_20p = pickle_method(op_5_fold_p20, 'rb', '')
print('k-folds: ', len(fold_5_20p))

fold_10_10p = pickle_method(op_10_fold_p10, 'rb', '')
print('k-folds: ', len(fold_10_10p))
fold_10_15p = pickle_method(op_10_fold_p15, 'rb', '')
print('k-folds: ', len(fold_10_15p))
fold_10_20p = pickle_method(op_10_fold_p20, 'rb', '')
print('k-folds: ', len(fold_10_20p))

fold_15_10p = pickle_method(op_15_fold_p10, 'rb', '')
print('k-folds: ', len(fold_15_10p))
fold_15_15p = pickle_method(op_15_fold_p15, 'rb', '')
print('k-folds: ', len(fold_15_15p))
fold_15_20p = pickle_method(op_15_fold_p20, 'rb', '')
print('k-folds: ', len(fold_15_20p))

fold_20_10p = pickle_method(op_20_fold_p10, 'rb', '')
print('k-folds: ', len(fold_20_10p))
fold_20_15p = pickle_method(op_20_fold_p15, 'rb', '')
print('k-folds: ', len(fold_20_15p))
fold_20_20p = pickle_method(op_20_fold_p20, 'rb', '')
print('k-folds: ', len(fold_20_20p))

# # print test
# print('Dictionary length: ', len(k_folds_dict))
# for fold in k_folds_dict:
#   print('\nFold: ', fold)
#   print('Total training features: ', len(k_folds_dict[fold][2]))
#   print('Total validation features: ', len(k_folds_dict[fold][3]))
#   print('Total training labels: ', len(k_folds_dict[fold][2]))
#   print('Total validation labels: ', len(k_folds_dict[fold][3]))

"""---


# **Modelling**
"""

# fit model to data
def fit_model_to_folds(model, k_folds_dict):
  scores = []
  i = 1
  print('\nModel: ', model)
  for fold in k_folds_dict:
    fitted_model = model.fit(k_folds_dict[fold][0], k_folds_dict[fold][2])
    score = accuracy_score(k_folds_dict[fold][3], fitted_model.predict(k_folds_dict[fold][1]))
    print('{} of KFold {}'.format(fold, len(k_folds_dict)), ' --> ROC AUC score:', score)
    scores.append(score)
    i += 1
  print("\nMean model score: %.3f" % statistics.mean(scores))
  return scores

def run_models(models, k_folds_dict):
  models_dict = {}
  for model in models:
    models_dict[str(model)] = fit_model_to_folds(model, k_folds_dict)
  return models_dict

# def run_k_folds =

from sklearn.naive_bayes import MultinomialNB
from sklearn.linear_model import LogisticRegression,SGDClassifier
from sklearn.svm import SVC
from sklearn.metrics import classification_report,confusion_matrix,accuracy_score

classifiers = [SGDClassifier(loss='hinge', random_state=random_seed)]

model_dict = run_models(classifiers, fold_5_10p)
model_dict = run_models(classifiers, fold_5_15p)
model_dict = run_models(classifiers, fold_5_20p)

model_dict = run_models(classifiers, fold_10_10p)
model_dict = run_models(classifiers, fold_10_15p)
model_dict = run_models(classifiers, fold_10_20p)

model_dict = run_models(classifiers, fold_15_10p)
model_dict = run_models(classifiers, fold_15_15p)
model_dict = run_models(classifiers, fold_15_20p)

model_dict = run_models(classifiers, fold_20_10p)
model_dict = run_models(classifiers, fold_20_15p)
model_dict = run_models(classifiers, fold_20_20p)

"""---"""

# # pickling atoxic protein data
# pickle_method(op_atoxic_atchley_final, 'wb', atoxic_list)

# # unpickling complete atoxic protein data
# atoxic_list = pickle_method(op_atoxic_atchley_complete, 'rb', '')